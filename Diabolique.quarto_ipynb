{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Les Diabolique (1955)\"\n",
        "author: \"Patrick E. McKnight\"\n",
        "format: html\n",
        "---"
      ],
      "id": "35d12d1c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "class MovieScraper:\n",
        "    def __init__(self):\n",
        "        self.headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        self.data = {\n",
        "            'ratings': [],\n",
        "            'reviews': [],\n",
        "            'metadata': {}\n",
        "        }\n",
        "\n",
        "    def scrape_letterboxd(self, movie_url):\n",
        "        \"\"\"\n",
        "        Scrape movie ratings and reviews from Letterboxd\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = requests.get(movie_url, headers=self.headers)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            \n",
        "            # Get overall rating\n",
        "            rating_elem = soup.find('meta', {'name': 'twitter:data2'})\n",
        "            if rating_elem:\n",
        "                self.data['metadata']['letterboxd_rating'] = float(rating_elem['content'].split('/')[0])\n",
        "            \n",
        "            # Get reviews\n",
        "            reviews = soup.find_all('div', class_='review-text')\n",
        "            for review in reviews:\n",
        "                self.data['reviews'].append({\n",
        "                    'source': 'Letterboxd',\n",
        "                    'text': review.get_text().strip(),\n",
        "                    'date': datetime.now().strftime('%Y-%m-%d')  # You might want to extract actual review dates\n",
        "                })\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping Letterboxd: {e}\")\n",
        "\n",
        "    def scrape_tmdb(self, api_key, movie_id):\n",
        "        \"\"\"\n",
        "        Scrape movie data from TMDB API\n",
        "        Note: You'll need to sign up for a free API key at https://www.themoviedb.org/\n",
        "        \"\"\"\n",
        "        base_url = f\"https://api.themoviedb.org/3/movie/{movie_id}\"\n",
        "        \n",
        "        try:\n",
        "            # Get movie details\n",
        "            response = requests.get(\n",
        "                f\"{base_url}?api_key={api_key}&language=en-US\"\n",
        "            ).json()\n",
        "            \n",
        "            self.data['metadata'].update({\n",
        "                'tmdb_rating': response.get('vote_average'),\n",
        "                'vote_count': response.get('vote_count'),\n",
        "                'popularity': response.get('popularity')\n",
        "            })\n",
        "            \n",
        "            # Get reviews\n",
        "            reviews = requests.get(\n",
        "                f\"{base_url}/reviews?api_key={api_key}&language=en-US\"\n",
        "            ).json()\n",
        "            \n",
        "            for review in reviews.get('results', []):\n",
        "                self.data['reviews'].append({\n",
        "                    'source': 'TMDB',\n",
        "                    'text': review.get('content'),\n",
        "                    'date': review.get('created_at')[:10]\n",
        "                })\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping TMDB: {e}\")\n",
        "\n",
        "    def export_data(self, filename):\n",
        "        \"\"\"\n",
        "        Export scraped data to CSV files\n",
        "        \"\"\"\n",
        "        # Export reviews\n",
        "        pd.DataFrame(self.data['reviews']).to_csv(f'{filename}_reviews.csv', index=False)\n",
        "        \n",
        "        # Export metadata\n",
        "        pd.DataFrame([self.data['metadata']]).to_csv(f'{filename}_metadata.csv', index=False)\n",
        "\n",
        "def main():\n",
        "    scraper = MovieScraper()\n",
        "    \n",
        "    # Example usage:\n",
        "    # You'll need to replace these with actual URLs and API keys\n",
        "    letterboxd_url = \"https://letterboxd.com/film/diabolique-1955/\"\n",
        "    tmdb_movie_id = \"11661\"  # ID for Les Diaboliques (1955)\n",
        "    tmdb_api_key = \"YOUR_API_KEY\"\n",
        "    \n",
        "    # Scrape data\n",
        "    scraper.scrape_letterboxd(letterboxd_url)\n",
        "    scraper.scrape_tmdb(tmdb_api_key, tmdb_movie_id)\n",
        "    \n",
        "    # Export data\n",
        "    scraper.export_data('diabolique_1955')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "id": "750240fa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}